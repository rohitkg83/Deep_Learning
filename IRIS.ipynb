{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IRIS.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO94zWIrXjBETU+i/nL5fGC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rohitkg83/Deep_Learning/blob/main/IRIS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Learning Model for predicting IRIS types\n",
        "\n",
        "This notebook aims to use neural networks for building a model that can predict three different types of irises - **Setosa, Versicolour and Virginica** from Sepal length, Sepal width, Petal length and Petal width. The dataset has been imported from scikit-learn and it has in total 150 observations. Tensorflow keras has been used for building the model."
      ],
      "metadata": {
        "id": "ZQIoojZfQphg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-ib5U5nCKB-M"
      },
      "outputs": [],
      "source": [
        "# Importing required libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "from keras.utils.np_utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up the seed for random number generators so that model reproduces same output when code is run\n",
        "np.random.seed(42)\n",
        "import random\n",
        "random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "IqUfMddYF6XG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset into iris and set-up predictor and target variables\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data[:]\n",
        "y = to_categorical(iris.target) # to_categorical performs onhot encoding of target variable"
      ],
      "metadata": {
        "id": "XlmmPCaTK3Sc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify shape of predictor\n",
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhFQhZSV6b5z",
        "outputId": "efaac9e5-f526-4c86-aea9-be6f26535ead"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Store number of predictor attributes in a variable\n",
        "n_cols = X.shape[1]"
      ],
      "metadata": {
        "id": "OjhVTX5JqyFA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify shape of target\n",
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYvXrEr_XGFX",
        "outputId": "74c06856-4446-413c-e7ab-297e24e5c949"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting the dataset into train and test data\n",
        "X_train, X_test, y_train, y_test =  train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "hwuvChMB6Eyp"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up model\n",
        "model = Sequential()\n",
        "\n",
        "# Add hidden layer with 32 nodes and use relu activation function\n",
        "model.add(Dense(32, activation='relu', input_shape=(n_cols,)))\n",
        "\n",
        "# Add output layer and use softmax activation function\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "# Compile the model using 'adam' optimizer, 'categorical_crossentropy' as loss function and 'accuracy' as the metrics for model performance\n",
        "model.compile(optimizer='adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "# Fit the model: use batch_size = 50 and epochs = 200\n",
        "history = model.fit(X,y, batch_size=50, epochs=200, validation_split=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XexvHx9ZUR4d",
        "outputId": "9a047c31-bba2-4ff3-bf81-76a8fbc9affc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "3/3 [==============================] - 2s 330ms/step - loss: 2.3876 - accuracy: 0.2593 - val_loss: 0.0698 - val_accuracy: 1.0000\n",
            "Epoch 2/200\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 2.1632 - accuracy: 0.2593 - val_loss: 0.1010 - val_accuracy: 1.0000\n",
            "Epoch 3/200\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 1.9618 - accuracy: 0.2593 - val_loss: 0.1440 - val_accuracy: 1.0000\n",
            "Epoch 4/200\n",
            "3/3 [==============================] - 0s 59ms/step - loss: 1.7693 - accuracy: 0.2593 - val_loss: 0.2008 - val_accuracy: 1.0000\n",
            "Epoch 5/200\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 1.6029 - accuracy: 0.2593 - val_loss: 0.2732 - val_accuracy: 1.0000\n",
            "Epoch 6/200\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.4613 - accuracy: 0.2593 - val_loss: 0.3618 - val_accuracy: 1.0000\n",
            "Epoch 7/200\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 1.3335 - accuracy: 0.2593 - val_loss: 0.4668 - val_accuracy: 1.0000\n",
            "Epoch 8/200\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 1.2374 - accuracy: 0.2593 - val_loss: 0.5823 - val_accuracy: 1.0000\n",
            "Epoch 9/200\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 1.1532 - accuracy: 0.2593 - val_loss: 0.6985 - val_accuracy: 1.0000\n",
            "Epoch 10/200\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 1.0969 - accuracy: 0.2593 - val_loss: 0.8112 - val_accuracy: 0.8667\n",
            "Epoch 11/200\n",
            "3/3 [==============================] - 0s 64ms/step - loss: 1.0499 - accuracy: 0.2296 - val_loss: 0.9065 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/200\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 1.0145 - accuracy: 0.3407 - val_loss: 0.9819 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/200\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.9833 - accuracy: 0.4370 - val_loss: 1.0377 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/200\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.9568 - accuracy: 0.6444 - val_loss: 1.0610 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/200\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 0.9293 - accuracy: 0.7407 - val_loss: 1.0675 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/200\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.9052 - accuracy: 0.7407 - val_loss: 1.0665 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/200\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.8819 - accuracy: 0.7407 - val_loss: 1.0429 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/200\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.8585 - accuracy: 0.7407 - val_loss: 1.0213 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/200\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.8374 - accuracy: 0.7407 - val_loss: 0.9864 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/200\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.8175 - accuracy: 0.7407 - val_loss: 0.9492 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/200\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.8001 - accuracy: 0.7407 - val_loss: 0.9112 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/200\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.7849 - accuracy: 0.7407 - val_loss: 0.8828 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/200\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.7702 - accuracy: 0.7481 - val_loss: 0.8625 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/200\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.7571 - accuracy: 0.7556 - val_loss: 0.8493 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/200\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.7445 - accuracy: 0.7556 - val_loss: 0.8385 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/200\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.7326 - accuracy: 0.7778 - val_loss: 0.8303 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/200\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.7211 - accuracy: 0.7852 - val_loss: 0.8230 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/200\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.7096 - accuracy: 0.7926 - val_loss: 0.8181 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.6984 - accuracy: 0.7926 - val_loss: 0.8233 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/200\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 0.6883 - accuracy: 0.7704 - val_loss: 0.8286 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/200\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.6784 - accuracy: 0.7704 - val_loss: 0.8224 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/200\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.6687 - accuracy: 0.7556 - val_loss: 0.8293 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/200\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 0.6595 - accuracy: 0.7556 - val_loss: 0.8345 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/200\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.6505 - accuracy: 0.7556 - val_loss: 0.8299 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.6419 - accuracy: 0.7556 - val_loss: 0.8231 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/200\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.6334 - accuracy: 0.7630 - val_loss: 0.8115 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/200\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.6250 - accuracy: 0.7630 - val_loss: 0.8034 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/200\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 0.6172 - accuracy: 0.7778 - val_loss: 0.7887 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/200\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.6094 - accuracy: 0.8074 - val_loss: 0.7780 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/200\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.6017 - accuracy: 0.8296 - val_loss: 0.7672 - val_accuracy: 0.2667\n",
            "Epoch 41/200\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.5944 - accuracy: 0.8519 - val_loss: 0.7517 - val_accuracy: 0.4000\n",
            "Epoch 42/200\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.5872 - accuracy: 0.8889 - val_loss: 0.7433 - val_accuracy: 0.4000\n",
            "Epoch 43/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.5802 - accuracy: 0.9111 - val_loss: 0.7339 - val_accuracy: 0.4667\n",
            "Epoch 44/200\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 0.5735 - accuracy: 0.9481 - val_loss: 0.7259 - val_accuracy: 0.6000\n",
            "Epoch 45/200\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.5670 - accuracy: 0.9481 - val_loss: 0.7220 - val_accuracy: 0.6000\n",
            "Epoch 46/200\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.5606 - accuracy: 0.9407 - val_loss: 0.7212 - val_accuracy: 0.6000\n",
            "Epoch 47/200\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 0.5543 - accuracy: 0.9407 - val_loss: 0.7188 - val_accuracy: 0.6000\n",
            "Epoch 48/200\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.5483 - accuracy: 0.9333 - val_loss: 0.7159 - val_accuracy: 0.6000\n",
            "Epoch 49/200\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.5427 - accuracy: 0.9407 - val_loss: 0.7047 - val_accuracy: 0.6667\n",
            "Epoch 50/200\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 0.5367 - accuracy: 0.9481 - val_loss: 0.7054 - val_accuracy: 0.6000\n",
            "Epoch 51/200\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 0.5311 - accuracy: 0.9481 - val_loss: 0.7028 - val_accuracy: 0.6000\n",
            "Epoch 52/200\n",
            "3/3 [==============================] - 0s 73ms/step - loss: 0.5257 - accuracy: 0.9481 - val_loss: 0.7028 - val_accuracy: 0.6000\n",
            "Epoch 53/200\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.5207 - accuracy: 0.9333 - val_loss: 0.7110 - val_accuracy: 0.5333\n",
            "Epoch 54/200\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.5154 - accuracy: 0.9333 - val_loss: 0.7170 - val_accuracy: 0.4667\n",
            "Epoch 55/200\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 0.5104 - accuracy: 0.9185 - val_loss: 0.7135 - val_accuracy: 0.4667\n",
            "Epoch 56/200\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.5055 - accuracy: 0.9185 - val_loss: 0.7114 - val_accuracy: 0.4667\n",
            "Epoch 57/200\n",
            "3/3 [==============================] - 0s 66ms/step - loss: 0.5014 - accuracy: 0.9185 - val_loss: 0.7088 - val_accuracy: 0.5333\n",
            "Epoch 58/200\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.4958 - accuracy: 0.9333 - val_loss: 0.6860 - val_accuracy: 0.6667\n",
            "Epoch 59/200\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.4915 - accuracy: 0.9407 - val_loss: 0.6614 - val_accuracy: 0.9333\n",
            "Epoch 60/200\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.4873 - accuracy: 0.9481 - val_loss: 0.6456 - val_accuracy: 0.9333\n",
            "Epoch 61/200\n",
            "3/3 [==============================] - 0s 57ms/step - loss: 0.4828 - accuracy: 0.9704 - val_loss: 0.6430 - val_accuracy: 0.9333\n",
            "Epoch 62/200\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.4785 - accuracy: 0.9630 - val_loss: 0.6436 - val_accuracy: 0.9333\n",
            "Epoch 63/200\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 0.4743 - accuracy: 0.9407 - val_loss: 0.6455 - val_accuracy: 0.9333\n",
            "Epoch 64/200\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.4701 - accuracy: 0.9407 - val_loss: 0.6462 - val_accuracy: 0.9333\n",
            "Epoch 65/200\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.4659 - accuracy: 0.9407 - val_loss: 0.6561 - val_accuracy: 0.8667\n",
            "Epoch 66/200\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.4620 - accuracy: 0.9407 - val_loss: 0.6673 - val_accuracy: 0.7333\n",
            "Epoch 67/200\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.4585 - accuracy: 0.9407 - val_loss: 0.6736 - val_accuracy: 0.7333\n",
            "Epoch 68/200\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.4546 - accuracy: 0.9407 - val_loss: 0.6687 - val_accuracy: 0.7333\n",
            "Epoch 69/200\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.4512 - accuracy: 0.9407 - val_loss: 0.6488 - val_accuracy: 0.8667\n",
            "Epoch 70/200\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 0.4470 - accuracy: 0.9407 - val_loss: 0.6412 - val_accuracy: 0.9333\n",
            "Epoch 71/200\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.4435 - accuracy: 0.9407 - val_loss: 0.6269 - val_accuracy: 0.9333\n",
            "Epoch 72/200\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.4398 - accuracy: 0.9407 - val_loss: 0.6216 - val_accuracy: 0.9333\n",
            "Epoch 73/200\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.4365 - accuracy: 0.9407 - val_loss: 0.6179 - val_accuracy: 0.9333\n",
            "Epoch 74/200\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.4331 - accuracy: 0.9556 - val_loss: 0.6046 - val_accuracy: 0.9333\n",
            "Epoch 75/200\n",
            "3/3 [==============================] - 0s 70ms/step - loss: 0.4299 - accuracy: 0.9778 - val_loss: 0.5944 - val_accuracy: 0.9333\n",
            "Epoch 76/200\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.4262 - accuracy: 0.9778 - val_loss: 0.5979 - val_accuracy: 0.9333\n",
            "Epoch 77/200\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.4230 - accuracy: 0.9630 - val_loss: 0.6041 - val_accuracy: 0.9333\n",
            "Epoch 78/200\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.4200 - accuracy: 0.9481 - val_loss: 0.6167 - val_accuracy: 0.9333\n",
            "Epoch 79/200\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 0.4166 - accuracy: 0.9407 - val_loss: 0.6126 - val_accuracy: 0.9333\n",
            "Epoch 80/200\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.4134 - accuracy: 0.9407 - val_loss: 0.6141 - val_accuracy: 0.9333\n",
            "Epoch 81/200\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 0.4102 - accuracy: 0.9407 - val_loss: 0.6092 - val_accuracy: 0.9333\n",
            "Epoch 82/200\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.4073 - accuracy: 0.9407 - val_loss: 0.6018 - val_accuracy: 0.9333\n",
            "Epoch 83/200\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.4041 - accuracy: 0.9407 - val_loss: 0.5931 - val_accuracy: 0.9333\n",
            "Epoch 84/200\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.4013 - accuracy: 0.9481 - val_loss: 0.5760 - val_accuracy: 0.9333\n",
            "Epoch 85/200\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.3983 - accuracy: 0.9704 - val_loss: 0.5723 - val_accuracy: 0.9333\n",
            "Epoch 86/200\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.3960 - accuracy: 0.9704 - val_loss: 0.5646 - val_accuracy: 0.9333\n",
            "Epoch 87/200\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.3923 - accuracy: 0.9704 - val_loss: 0.5741 - val_accuracy: 0.9333\n",
            "Epoch 88/200\n",
            "3/3 [==============================] - 0s 60ms/step - loss: 0.3894 - accuracy: 0.9556 - val_loss: 0.5822 - val_accuracy: 0.9333\n",
            "Epoch 89/200\n",
            "3/3 [==============================] - 0s 70ms/step - loss: 0.3871 - accuracy: 0.9407 - val_loss: 0.5941 - val_accuracy: 0.9333\n",
            "Epoch 90/200\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.3842 - accuracy: 0.9407 - val_loss: 0.5849 - val_accuracy: 0.9333\n",
            "Epoch 91/200\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.3812 - accuracy: 0.9407 - val_loss: 0.5794 - val_accuracy: 0.9333\n",
            "Epoch 92/200\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.3786 - accuracy: 0.9407 - val_loss: 0.5790 - val_accuracy: 0.9333\n",
            "Epoch 93/200\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 0.3758 - accuracy: 0.9407 - val_loss: 0.5702 - val_accuracy: 0.9333\n",
            "Epoch 94/200\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 0.3730 - accuracy: 0.9481 - val_loss: 0.5585 - val_accuracy: 0.9333\n",
            "Epoch 95/200\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.3707 - accuracy: 0.9630 - val_loss: 0.5443 - val_accuracy: 0.9333\n",
            "Epoch 96/200\n",
            "3/3 [==============================] - 0s 59ms/step - loss: 0.3679 - accuracy: 0.9704 - val_loss: 0.5386 - val_accuracy: 1.0000\n",
            "Epoch 97/200\n",
            "3/3 [==============================] - 0s 69ms/step - loss: 0.3654 - accuracy: 0.9704 - val_loss: 0.5403 - val_accuracy: 0.9333\n",
            "Epoch 98/200\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.3628 - accuracy: 0.9704 - val_loss: 0.5335 - val_accuracy: 1.0000\n",
            "Epoch 99/200\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.3602 - accuracy: 0.9704 - val_loss: 0.5373 - val_accuracy: 0.9333\n",
            "Epoch 100/200\n",
            "3/3 [==============================] - 0s 61ms/step - loss: 0.3577 - accuracy: 0.9704 - val_loss: 0.5427 - val_accuracy: 0.9333\n",
            "Epoch 101/200\n",
            "3/3 [==============================] - 0s 67ms/step - loss: 0.3554 - accuracy: 0.9556 - val_loss: 0.5472 - val_accuracy: 0.9333\n",
            "Epoch 102/200\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.3527 - accuracy: 0.9556 - val_loss: 0.5378 - val_accuracy: 0.9333\n",
            "Epoch 103/200\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.3506 - accuracy: 0.9630 - val_loss: 0.5224 - val_accuracy: 1.0000\n",
            "Epoch 104/200\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.3481 - accuracy: 0.9704 - val_loss: 0.5229 - val_accuracy: 0.9333\n",
            "Epoch 105/200\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.3454 - accuracy: 0.9704 - val_loss: 0.5193 - val_accuracy: 0.9333\n",
            "Epoch 106/200\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.3431 - accuracy: 0.9778 - val_loss: 0.5091 - val_accuracy: 1.0000\n",
            "Epoch 107/200\n",
            "3/3 [==============================] - 0s 70ms/step - loss: 0.3408 - accuracy: 0.9778 - val_loss: 0.5064 - val_accuracy: 1.0000\n",
            "Epoch 108/200\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.3385 - accuracy: 0.9778 - val_loss: 0.5089 - val_accuracy: 1.0000\n",
            "Epoch 109/200\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.3362 - accuracy: 0.9704 - val_loss: 0.5102 - val_accuracy: 0.9333\n",
            "Epoch 110/200\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.3337 - accuracy: 0.9704 - val_loss: 0.5127 - val_accuracy: 0.9333\n",
            "Epoch 111/200\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 0.3319 - accuracy: 0.9630 - val_loss: 0.5248 - val_accuracy: 0.9333\n",
            "Epoch 112/200\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.3298 - accuracy: 0.9481 - val_loss: 0.5230 - val_accuracy: 0.9333\n",
            "Epoch 113/200\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.3272 - accuracy: 0.9556 - val_loss: 0.5090 - val_accuracy: 0.9333\n",
            "Epoch 114/200\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 0.3250 - accuracy: 0.9704 - val_loss: 0.4925 - val_accuracy: 1.0000\n",
            "Epoch 115/200\n",
            "3/3 [==============================] - 0s 79ms/step - loss: 0.3229 - accuracy: 0.9852 - val_loss: 0.4806 - val_accuracy: 1.0000\n",
            "Epoch 116/200\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.3209 - accuracy: 0.9852 - val_loss: 0.4856 - val_accuracy: 1.0000\n",
            "Epoch 117/200\n",
            "3/3 [==============================] - 0s 59ms/step - loss: 0.3186 - accuracy: 0.9778 - val_loss: 0.4773 - val_accuracy: 1.0000\n",
            "Epoch 118/200\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.3167 - accuracy: 0.9778 - val_loss: 0.4849 - val_accuracy: 1.0000\n",
            "Epoch 119/200\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 0.3142 - accuracy: 0.9778 - val_loss: 0.4897 - val_accuracy: 0.9333\n",
            "Epoch 120/200\n",
            "3/3 [==============================] - 0s 62ms/step - loss: 0.3122 - accuracy: 0.9704 - val_loss: 0.4871 - val_accuracy: 0.9333\n",
            "Epoch 121/200\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 0.3100 - accuracy: 0.9704 - val_loss: 0.4792 - val_accuracy: 1.0000\n",
            "Epoch 122/200\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.3080 - accuracy: 0.9704 - val_loss: 0.4730 - val_accuracy: 1.0000\n",
            "Epoch 123/200\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 0.3060 - accuracy: 0.9778 - val_loss: 0.4676 - val_accuracy: 1.0000\n",
            "Epoch 124/200\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.3039 - accuracy: 0.9778 - val_loss: 0.4534 - val_accuracy: 1.0000\n",
            "Epoch 125/200\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.3022 - accuracy: 0.9778 - val_loss: 0.4465 - val_accuracy: 1.0000\n",
            "Epoch 126/200\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.3003 - accuracy: 0.9852 - val_loss: 0.4553 - val_accuracy: 1.0000\n",
            "Epoch 127/200\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.2980 - accuracy: 0.9778 - val_loss: 0.4665 - val_accuracy: 1.0000\n",
            "Epoch 128/200\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.2961 - accuracy: 0.9704 - val_loss: 0.4656 - val_accuracy: 1.0000\n",
            "Epoch 129/200\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.2941 - accuracy: 0.9704 - val_loss: 0.4682 - val_accuracy: 0.9333\n",
            "Epoch 130/200\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2926 - accuracy: 0.9630 - val_loss: 0.4701 - val_accuracy: 0.9333\n",
            "Epoch 131/200\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.2905 - accuracy: 0.9630 - val_loss: 0.4623 - val_accuracy: 0.9333\n",
            "Epoch 132/200\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 0.2886 - accuracy: 0.9704 - val_loss: 0.4386 - val_accuracy: 1.0000\n",
            "Epoch 133/200\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.2865 - accuracy: 0.9778 - val_loss: 0.4289 - val_accuracy: 1.0000\n",
            "Epoch 134/200\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.2850 - accuracy: 0.9778 - val_loss: 0.4196 - val_accuracy: 1.0000\n",
            "Epoch 135/200\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.2830 - accuracy: 0.9778 - val_loss: 0.4231 - val_accuracy: 1.0000\n",
            "Epoch 136/200\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.2811 - accuracy: 0.9852 - val_loss: 0.4318 - val_accuracy: 1.0000\n",
            "Epoch 137/200\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.2791 - accuracy: 0.9778 - val_loss: 0.4411 - val_accuracy: 1.0000\n",
            "Epoch 138/200\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.2775 - accuracy: 0.9704 - val_loss: 0.4517 - val_accuracy: 0.9333\n",
            "Epoch 139/200\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.2758 - accuracy: 0.9630 - val_loss: 0.4498 - val_accuracy: 0.9333\n",
            "Epoch 140/200\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.2747 - accuracy: 0.9630 - val_loss: 0.4474 - val_accuracy: 0.9333\n",
            "Epoch 141/200\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.2729 - accuracy: 0.9704 - val_loss: 0.4321 - val_accuracy: 1.0000\n",
            "Epoch 142/200\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.2706 - accuracy: 0.9778 - val_loss: 0.4272 - val_accuracy: 1.0000\n",
            "Epoch 143/200\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.2689 - accuracy: 0.9778 - val_loss: 0.4218 - val_accuracy: 1.0000\n",
            "Epoch 144/200\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.2671 - accuracy: 0.9778 - val_loss: 0.4100 - val_accuracy: 1.0000\n",
            "Epoch 145/200\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.2653 - accuracy: 0.9778 - val_loss: 0.4037 - val_accuracy: 1.0000\n",
            "Epoch 146/200\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 0.2647 - accuracy: 0.9778 - val_loss: 0.3927 - val_accuracy: 1.0000\n",
            "Epoch 147/200\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.2621 - accuracy: 0.9778 - val_loss: 0.4046 - val_accuracy: 1.0000\n",
            "Epoch 148/200\n",
            "3/3 [==============================] - 0s 57ms/step - loss: 0.2603 - accuracy: 0.9778 - val_loss: 0.4170 - val_accuracy: 1.0000\n",
            "Epoch 149/200\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.2592 - accuracy: 0.9704 - val_loss: 0.4265 - val_accuracy: 0.9333\n",
            "Epoch 150/200\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.2576 - accuracy: 0.9704 - val_loss: 0.4206 - val_accuracy: 0.9333\n",
            "Epoch 151/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.2560 - accuracy: 0.9630 - val_loss: 0.4151 - val_accuracy: 1.0000\n",
            "Epoch 152/200\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.2540 - accuracy: 0.9778 - val_loss: 0.3984 - val_accuracy: 1.0000\n",
            "Epoch 153/200\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.2529 - accuracy: 0.9778 - val_loss: 0.3895 - val_accuracy: 1.0000\n",
            "Epoch 154/200\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 0.2511 - accuracy: 0.9852 - val_loss: 0.3640 - val_accuracy: 1.0000\n",
            "Epoch 155/200\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2502 - accuracy: 0.9778 - val_loss: 0.3537 - val_accuracy: 1.0000\n",
            "Epoch 156/200\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.2485 - accuracy: 0.9778 - val_loss: 0.3590 - val_accuracy: 1.0000\n",
            "Epoch 157/200\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.2467 - accuracy: 0.9778 - val_loss: 0.3794 - val_accuracy: 1.0000\n",
            "Epoch 158/200\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.2447 - accuracy: 0.9778 - val_loss: 0.3930 - val_accuracy: 1.0000\n",
            "Epoch 159/200\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.2433 - accuracy: 0.9778 - val_loss: 0.4010 - val_accuracy: 1.0000\n",
            "Epoch 160/200\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.2423 - accuracy: 0.9704 - val_loss: 0.4029 - val_accuracy: 0.9333\n",
            "Epoch 161/200\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 0.2407 - accuracy: 0.9704 - val_loss: 0.3926 - val_accuracy: 1.0000\n",
            "Epoch 162/200\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 0.2390 - accuracy: 0.9778 - val_loss: 0.3770 - val_accuracy: 1.0000\n",
            "Epoch 163/200\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 0.2377 - accuracy: 0.9778 - val_loss: 0.3682 - val_accuracy: 1.0000\n",
            "Epoch 164/200\n",
            "3/3 [==============================] - 0s 73ms/step - loss: 0.2360 - accuracy: 0.9778 - val_loss: 0.3517 - val_accuracy: 1.0000\n",
            "Epoch 165/200\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.2351 - accuracy: 0.9778 - val_loss: 0.3385 - val_accuracy: 1.0000\n",
            "Epoch 166/200\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 0.2341 - accuracy: 0.9778 - val_loss: 0.3439 - val_accuracy: 1.0000\n",
            "Epoch 167/200\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.2328 - accuracy: 0.9778 - val_loss: 0.3509 - val_accuracy: 1.0000\n",
            "Epoch 168/200\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 0.2307 - accuracy: 0.9778 - val_loss: 0.3478 - val_accuracy: 1.0000\n",
            "Epoch 169/200\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.2296 - accuracy: 0.9778 - val_loss: 0.3511 - val_accuracy: 1.0000\n",
            "Epoch 170/200\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 0.2282 - accuracy: 0.9778 - val_loss: 0.3509 - val_accuracy: 1.0000\n",
            "Epoch 171/200\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.2269 - accuracy: 0.9778 - val_loss: 0.3467 - val_accuracy: 1.0000\n",
            "Epoch 172/200\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.2256 - accuracy: 0.9852 - val_loss: 0.3503 - val_accuracy: 1.0000\n",
            "Epoch 173/200\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.2241 - accuracy: 0.9852 - val_loss: 0.3442 - val_accuracy: 1.0000\n",
            "Epoch 174/200\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.2228 - accuracy: 0.9778 - val_loss: 0.3426 - val_accuracy: 1.0000\n",
            "Epoch 175/200\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.2216 - accuracy: 0.9778 - val_loss: 0.3474 - val_accuracy: 1.0000\n",
            "Epoch 176/200\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 0.2202 - accuracy: 0.9778 - val_loss: 0.3515 - val_accuracy: 1.0000\n",
            "Epoch 177/200\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2190 - accuracy: 0.9778 - val_loss: 0.3517 - val_accuracy: 1.0000\n",
            "Epoch 178/200\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.2178 - accuracy: 0.9778 - val_loss: 0.3484 - val_accuracy: 1.0000\n",
            "Epoch 179/200\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.2164 - accuracy: 0.9778 - val_loss: 0.3388 - val_accuracy: 1.0000\n",
            "Epoch 180/200\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.2153 - accuracy: 0.9852 - val_loss: 0.3314 - val_accuracy: 1.0000\n",
            "Epoch 181/200\n",
            "3/3 [==============================] - 0s 58ms/step - loss: 0.2142 - accuracy: 0.9778 - val_loss: 0.3309 - val_accuracy: 1.0000\n",
            "Epoch 182/200\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.2128 - accuracy: 0.9778 - val_loss: 0.3218 - val_accuracy: 1.0000\n",
            "Epoch 183/200\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.2120 - accuracy: 0.9778 - val_loss: 0.3155 - val_accuracy: 1.0000\n",
            "Epoch 184/200\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.2111 - accuracy: 0.9778 - val_loss: 0.3286 - val_accuracy: 1.0000\n",
            "Epoch 185/200\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.2093 - accuracy: 0.9778 - val_loss: 0.3290 - val_accuracy: 1.0000\n",
            "Epoch 186/200\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.2082 - accuracy: 0.9778 - val_loss: 0.3318 - val_accuracy: 1.0000\n",
            "Epoch 187/200\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.2070 - accuracy: 0.9778 - val_loss: 0.3292 - val_accuracy: 1.0000\n",
            "Epoch 188/200\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.2064 - accuracy: 0.9778 - val_loss: 0.3167 - val_accuracy: 1.0000\n",
            "Epoch 189/200\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 0.2047 - accuracy: 0.9778 - val_loss: 0.3198 - val_accuracy: 1.0000\n",
            "Epoch 190/200\n",
            "3/3 [==============================] - 0s 58ms/step - loss: 0.2036 - accuracy: 0.9778 - val_loss: 0.3211 - val_accuracy: 1.0000\n",
            "Epoch 191/200\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.2027 - accuracy: 0.9778 - val_loss: 0.3270 - val_accuracy: 1.0000\n",
            "Epoch 192/200\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.2014 - accuracy: 0.9778 - val_loss: 0.3237 - val_accuracy: 1.0000\n",
            "Epoch 193/200\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.2003 - accuracy: 0.9778 - val_loss: 0.3156 - val_accuracy: 1.0000\n",
            "Epoch 194/200\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.1993 - accuracy: 0.9778 - val_loss: 0.3061 - val_accuracy: 1.0000\n",
            "Epoch 195/200\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 0.1981 - accuracy: 0.9778 - val_loss: 0.3015 - val_accuracy: 1.0000\n",
            "Epoch 196/200\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.1972 - accuracy: 0.9778 - val_loss: 0.2985 - val_accuracy: 1.0000\n",
            "Epoch 197/200\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.1966 - accuracy: 0.9778 - val_loss: 0.3057 - val_accuracy: 1.0000\n",
            "Epoch 198/200\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 0.1950 - accuracy: 0.9778 - val_loss: 0.3006 - val_accuracy: 1.0000\n",
            "Epoch 199/200\n",
            "3/3 [==============================] - 0s 65ms/step - loss: 0.1942 - accuracy: 0.9778 - val_loss: 0.2919 - val_accuracy: 1.0000\n",
            "Epoch 200/200\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.1931 - accuracy: 0.9778 - val_loss: 0.2859 - val_accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting Accuracy of Training and Validation set against Epochs\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Accuracy vs Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "eYjRiD8q8VLO",
        "outputId": "7cd21f0c-2898-4ca6-c2a9-5ac53bbd2446"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model evaluation on the test set\n",
        "model.evaluate(X_test, y_test, verbose = 1)\n",
        "test_pred = np.round(model.predict(X_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyEXAMGw9TB1",
        "outputId": "b9700077-ebae-4ba2-e250-13a5ae1c6b6f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 38ms/step - loss: 0.2022 - accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing the classification report\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, test_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftYj5RZU9d8a",
        "outputId": "b6fd0e9e-040a-4e76-e0be-15b8a971626c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      1.00      1.00         9\n",
            "           2       1.00      1.00      1.00        11\n",
            "\n",
            "   micro avg       1.00      1.00      1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            " samples avg       1.00      1.00      1.00        30\n",
            "\n"
          ]
        }
      ]
    }
  ]
}